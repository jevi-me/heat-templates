heat_template_version: 2015-04-30

description: '''
  Boot a Kubernetes cluster with a single master and one or more nodes (as specified)
  OpenStack Powered Cloud.'''

parameters:

  flavor:
    description: Flavor used for instances
    label: Flavor
    type: string
    default: 83867183-2096-4d41-945b-953a5876b575
    hidden: false
    constraints:
    - custom_constraint: nova.flavor
    description: Valid flavors only

  image:
    description: Image that will be used for the nodes.
    label: Image
    type: string
    default: 2cd245b5-9290-45d6-87fe-69c0b837659f
    hidden: false
    constraints: 
    - custom_constraint: glance.image
    description: Must be a valid Glance image

  k8s_node_count:
    description: Number of machines to deploy as a Kubernetes Minion
    label: Kubernetes Minion Count
    type: number
    default: 1
    hidden: false
    constraints:
    - range:
        min: 1
        max: 6
      description: Must be between 2 and 6 machines.

  ext_network:
    description: See Routers tab for name of the External Network
    type: string
    label: External Network
    default: VLAN3337
    hidden: false

  keyname:
    description: Name of keypair to be used for instance
    label: Key Pair
    type: string
    default: dtnode_key
    hidden: false
    constraints: 
    - custom_constraint: nova.keypair
    description: Must be a known keypair

  network_resource:
    description: WestGrid project network
    label: Network
    type: string
    default: a7741f95-0bc1-4424-86ef-2e8f66bcae18
    hidden: false
    constraints:
    - custom_constraint: neutron.network
    description: Must be a valid Neutron Network.

  docker_volume_size:
    type: number
    description: size of a cinder volume to allocate to docker for container/image storage
    default: 1

resources:
  ########################################
  ##  Policies, Alarm, Groups and IPs
  ########################################
  scale_up_policy:
    depends_on:
      - k8s_nodes
    type: OS::Heat::ScalingPolicy
    properties:
      adjustment_type: change_in_capacity
      auto_scaling_group_id: { get_resource: k8s_nodes }
      cooldown: 120
      scaling_adjustment: 1

  scale_down_policy:
    depends_on:
      - k8s_nodes
    type: OS::Heat::ScalingPolicy
    properties:
      adjustment_type: change_in_capacity
      auto_scaling_group_id: { get_resource: k8s_nodes }
      cooldown: 60
      scaling_adjustment: -1

  server_group:
    type: OS::Nova::ServerGroup
    properties:
      name: nova-server-group

  kube_master_floating:
    type: OS::Nova::FloatingIP
    properties:
      pool: {get_param: ext_network}

  kube_master_floating_association:
    type: OS::Nova::FloatingIPAssociation
    depends_on:
      - k8s_master
    properties:
      floating_ip: {get_resource: kube_master_floating}
      server_id: {get_resource: k8s_master}

  cluster_access:
     type: OS::Neutron::SecurityGroup
     properties:
       name: cluster_access
       rules:
         - remote_ip_prefix: 0.0.0.0/0
           protocol: tcp
           port_range_min: 22
           port_range_max: 22
         - remote_ip_prefix: 0.0.0.0/0
           protocol: tcp
           port_range_min: 10250
           port_range_max: 10255
         - remote_ip_prefix: 0.0.0.0/0
           protocol: tcp
           port_range_min: 2379
           port_range_max: 2380
         - remote_ip_prefix: 0.0.0.0/0
           protocol: tcp
           port_range_min: 6443
           port_range_max: 6443
         - remote_ip_prefix: 0.0.0.0/0
           protocol: tcp
           port_range_min: 30000
           port_range_max: 32767
         - remote_ip_prefix: 0.0.0.0/0
           protocol: tcp
           port_range_min: 1
           port_range_max: 65535
         - remote_ip_prefix: 0.0.0.0/0
           protocol: udp
           port_range_min: 1
           port_range_max: 65535
         - remote_ip_prefix: 0.0.0.0/0
           protocol: icmp

  ########################################
  ##  Software Config Parts (Master)
  ########################################
  variables_init:
    type: OS::Heat::SoftwareConfig        
    properties:
      group: ungrouped
      config: |
        #!/bin/sh
        yum upgrade -y -q 
        systemctl disable firewalld
        sed -i 's/SELINUX=.*/SELINUX=disabled/' /etc/selinux/config
        yum remove chrony -y -q
        yum install ntp -y -q
        systemctl enable ntpd.service
        systemctl start ntpd.service

  install_packages_master:
    type: OS::Heat::SoftwareConfig        
    properties:
      group: ungrouped
      config: |
        #!/bin/sh
        sudo su -
        yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/kubernetes-client-1.1.0-0.4.git2bfa9a1.el7.x86_64.rpm -y -q
        yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/kubernetes-master-1.1.0-0.4.git2bfa9a1.el7.x86_64.rpm -y -q
        yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/kubernetes-node-1.1.0-0.4.git2bfa9a1.el7.x86_64.rpm -y -q 
        yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/kubernetes-1.1.0-0.4.git2bfa9a1.el7.x86_64.rpm -y -q
        yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/etcd-2.0.9-1.el7.x86_64.rpm -y -q
        yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/flannel-0.2.0-7.el7.x86_64.rpm -y -q

  configure_files_master:
    type: OS::Heat::SoftwareConfig        
    properties:
      group: ungrouped
      config: |
        #!/bin/sh
        sudo su -
        masterip=$(ip addr show eth0 | awk '$1 == "inet" {print $2}' | cut -f1 -d/)
        cat <<EOF >> /etc/hosts
        $masterip    k8s-master.westcloud
        $masterip    k8s-master
        EOF
        mkdir /etc/kubernetes/originals-backup
        echo "This folder contains the original copies of all files modified by this script." > /etc/kubernetes/originals-backup/readme.txt
        cp /etc/kubernetes/apiserver /etc/kubernetes/originals-backup/apiserver
        cp /etc/kubernetes/config /etc/kubernetes/originals-backup/config
        cp /etc/etcd/etcd.conf /etc/kubernetes/originals-backup/etcd.conf
        cp /etc/kubernetes/kubelet /etc/kubernetes/originals-backup/kubelet
        cp /etc/sysconfig/flanneld /etc/kubernetes/originals-backup/flanneld
        cp /etc/kubernetes/controller-manager /etc/kubernetes/originals-backup/controller-manager
        cp /etc/sysconfig/docker  /etc/kubernetes/originals-backup/docker
        cat <<EOF > /etc/kubernetes/apiserver
        # The address on the local server to listen to.
        KUBE_API_ADDRESS="--insecure-bind-address=0.0.0.0"
        # The port on the local server to listen on.
        KUBE_API_PORT="--port=8080"
        # Port minions listen on
        KUBELET_PORT="--kubelet-port=10250"
        # Comma separated list of nodes in the etcd cluster
        KUBE_ETCD_SERVERS="--etcd-servers=http://k8s-master:2379,http://k8s-master:4001"
        # Address range to use for services
        KUBE_SERVICE_ADDRESSES="--service-cluster-ip-range=10.254.0.0/16"
        # default admission control policies
        KUBE_ADMISSION_CONTROL="--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota"
        # Add your own!
        KUBE_API_ARGS=""
        EOF
        cat <<EOF > /etc/kubernetes/config
        # logging to stderr means we get it in the systemd journal
        KUBE_LOGTOSTDERR="--logtostderr=true"
        # journal message level, 0 is debug
        KUBE_LOG_LEVEL="--v=0"
        # Should this cluster be allowed to run privileged docker containers
        KUBE_ALLOW_PRIV="--allow-privileged=false"
        # How the controller-manager, scheduler, and proxy find the apiserver
        KUBE_MASTER="--master=http://k8s-master:8080"
        EOF
        cat <<EOF > /etc/etcd/etcd.conf
        # [member]
        ETCD_NAME=default
        ETCD_DATA_DIR="/var/lib/etcd/default.etcd"
        ETCD_LISTEN_CLIENT_URLS="http://0.0.0.0:2379,http://0.0.0.0:4001"
        #[cluster]
        ETCD_ADVERTISE_CLIENT_URLS="http://0.0.0.0:2379,http://0.0.0.0:4001"
        EOF
        cat <<EOF > /etc/kubernetes/kubelet
        # The address for the info server to serve on (set to 0.0.0.0 or "" for all interfaces)
        KUBELET_ADDRESS="--address=0.0.0.0"
        # You may leave this blank to use the actual hostname
        KUBELET_HOSTNAME=""
        # location of the api-server
        KUBELET_API_SERVER="--api-servers=http://k8s-master:8080"
        # Add your own!
        KUBELET_ARGS=""
        EOF
        cat <<EOF > /etc/kubernetes/cloud.conf
        [Global]
        auth-url=https://west.cloud.computecanada.ca:5000/v2.0
        tenant-id=<REMOVED>
        username=<REMOVED>
        password=<REMOVED>
        EOF
        cat <<EOF > /etc/sysconfig/flanneld
        # etcd url location.  Point this to the server where etcd runs
        FLANNEL_ETCD="http://k8s-master:4001"
        # etcd config key.  This is the configuration key that flannel queries
        # For address range assignment
        FLANNEL_ETCD_KEY="/kube-centos/network"
        EOF
        sed -i 's/KUBE_CONTROLLER_MANAGER_ARGS=.*/KUBE_CONTROLLER_MANAGER_ARGS=\"--cloud-provider=openstack --cloud-config=\/etc\/kubernetes\/cloud.conf\"/' /etc/kubernetes/controller-manager
        sed -i 's/OPTIONS=.*/OPTIONS=\"--selinux-enabled=false --log-driver=journald --signature-verification=false\"/' /etc/sysconfig/docker

  start_services_master:
    type: OS::Heat::SoftwareConfig        
    properties:
      group: ungrouped
      config: |
        #!/bin/sh
        sudo su -
        systemctl enable --now etcd
        etcdctl mkdir /kube-centos/network
        etcdctl mk /kube-centos/network/config "{ \"Network\": \"172.30.30.0/12\", \"SubnetLen\": 24, \"Backend\": { \"Type\": \"vxlan\" } }"
        systemctl daemon-reload
        systemctl restart etcd
        systemctl enable --now kube-apiserver
        cat <<EOF >> /usr/lib/systemd/system/kube-apiserver.service
        [Service]
        PermissionsStartOnly=yes
        ExecStartPre=/usr/bin/mkdir -p /var/run/kubernetes
        ExecStartPre=/usr/bin/chown kube.kube /var/run/kubernetes
        EOF
        systemctl daemon-reload
        systemctl restart kube-apiserver
        for service in kube-controller-manager flanneld kube-scheduler docker kube-proxy kubelet; do 
          systemctl enable --now $service
        done
        kubectl config set-cluster default-cluster --server=http://k8s-master:8080
        kubectl config set-context default-context --cluster=default-cluster --user=default-admin
        kubectl config use-context default-context
        systemctl is-system-running
        for service in etcd kube-apiserver kube-controller-manager flanneld kube-scheduler docker kube-proxy kubelet; do 
          systemctl status -l $service
        done
        kubectl get nodes

  ### INIT BUILD
  kube_master_init:
    type: OS::Heat::MultipartMime
    properties:
      parts:
        - config: {get_resource: variables_init}
        - config: {get_resource: install_packages_master}
        - config: {get_resource: configure_files_master}
        - config: {get_resource: start_services_master}

  ########################################
  ##  Servers
  ########################################
  k8s_master:
    type: OS::Nova::Server
    properties:
      name: k8s_master
      image:    { get_param: image   }
      flavor:   { get_param: flavor  }
      key_name: { get_param: keyname }
      networks: 
      - network: { get_param: network_resource }
      scheduler_hints: { group: { get_resource: server_group } }
      security_groups: 
      - default
      - get_resource: cluster_access
      metadata: 
        kube_group: k8scluster,vault,nofloating
      user_data_format: RAW
      user_data: 
        user_data:
          str_replace:
            template: |
              #!/bin/sh
              yum upgrade -y -q 
              systemctl disable firewalld
              sed -i 's/SELINUX=.*/SELINUX=disabled/' /etc/selinux/config
              yum remove chrony -y -q
              yum install ntp -y -q
              systemctl enable ntpd.service
              systemctl start ntpd.service

              yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/kubernetes-client-1.1.0-0.4.git2bfa9a1.el7.x86_64.rpm -y -q
              yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/kubernetes-master-1.1.0-0.4.git2bfa9a1.el7.x86_64.rpm -y -q
              yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/kubernetes-node-1.1.0-0.4.git2bfa9a1.el7.x86_64.rpm -y -q 
              yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/kubernetes-1.1.0-0.4.git2bfa9a1.el7.x86_64.rpm -y -q
              yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/etcd-2.0.9-1.el7.x86_64.rpm -y -q
              yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/flannel-0.2.0-7.el7.x86_64.rpm -y -q

              masterip=$(ip addr show eth0 | awk '$1 == "inet" {print $2}' | cut -f1 -d/)
              cat <<EOF >> /etc/hosts
              $masterip    k8s-master.westcloud
              $masterip    k8s-master
              EOF
              mkdir /etc/kubernetes/originals-backup
              echo "This folder contains the original copies of all files modified by this script." > /etc/kubernetes/originals-backup/readme.txt
              cp /etc/kubernetes/apiserver /etc/kubernetes/originals-backup/apiserver
              cp /etc/kubernetes/config /etc/kubernetes/originals-backup/config
              cp /etc/etcd/etcd.conf /etc/kubernetes/originals-backup/etcd.conf
              cp /etc/kubernetes/kubelet /etc/kubernetes/originals-backup/kubelet
              cp /etc/sysconfig/flanneld /etc/kubernetes/originals-backup/flanneld
              cp /etc/kubernetes/controller-manager /etc/kubernetes/originals-backup/controller-manager
              cp /etc/sysconfig/docker  /etc/kubernetes/originals-backup/docker

              cat <<EOF > /etc/kubernetes/apiserver
              # The address on the local server to listen to.
              KUBE_API_ADDRESS="--insecure-bind-address=0.0.0.0"
              # The port on the local server to listen on.
              KUBE_API_PORT="--port=8080"
              # Port minions listen on
              KUBELET_PORT="--kubelet-port=10250"
              # Comma separated list of nodes in the etcd cluster
              KUBE_ETCD_SERVERS="--etcd-servers=http://k8s-master:2379,http://k8s-master:4001"
              # Address range to use for services
              KUBE_SERVICE_ADDRESSES="--service-cluster-ip-range=10.254.0.0/16"
              # default admission control policies
              KUBE_ADMISSION_CONTROL="--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota"
              # Add your own!
              KUBE_API_ARGS=""
              EOF

              cat <<EOF > /etc/kubernetes/config
              # logging to stderr means we get it in the systemd journal
              KUBE_LOGTOSTDERR="--logtostderr=true"
              # journal message level, 0 is debug
              KUBE_LOG_LEVEL="--v=0"
              # Should this cluster be allowed to run privileged docker containers
              KUBE_ALLOW_PRIV="--allow-privileged=false"
              # How the controller-manager, scheduler, and proxy find the apiserver
              KUBE_MASTER="--master=http://k8s-master:8080"
              EOF

              cat <<EOF > /etc/etcd/etcd.conf
              # [member]
              ETCD_NAME=default
              ETCD_DATA_DIR="/var/lib/etcd/default.etcd"
              ETCD_LISTEN_CLIENT_URLS="http://0.0.0.0:2379,http://0.0.0.0:4001"
              #[cluster]
              ETCD_ADVERTISE_CLIENT_URLS="http://0.0.0.0:2379,http://0.0.0.0:4001"
              EOF

              cat <<EOF > /etc/kubernetes/kubelet
              # The address for the info server to serve on (set to 0.0.0.0 or "" for all interfaces)
              KUBELET_ADDRESS="--address=0.0.0.0"
              # You may leave this blank to use the actual hostname
              KUBELET_HOSTNAME=""
              # location of the api-server
              KUBELET_API_SERVER="--api-servers=http://k8s-master:8080"
              # Add your own!
              KUBELET_ARGS=""
              EOF

              cat <<EOF > /etc/kubernetes/cloud.conf
              [Global]
              auth-url=%ostack_auth_url%
              tenant-id=%ostack_tenant%
              username=%ostack_username%
              password=%ostack_password%
              EOF

              cat <<EOF > /etc/sysconfig/flanneld
              # etcd url location.  Point this to the server where etcd runs
              FLANNEL_ETCD="http://k8s-master:4001"
              # etcd config key.  This is the configuration key that flannel queries
              # For address range assignment
              FLANNEL_ETCD_KEY="/kube-centos/network"
              EOF

              sed -i 's/KUBE_CONTROLLER_MANAGER_ARGS=.*/KUBE_CONTROLLER_MANAGER_ARGS=\"--cloud-provider=openstack --cloud-config=\/etc\/kubernetes\/cloud.conf\"/' /etc/kubernetes/controller-manager
              sed -i 's/OPTIONS=.*/OPTIONS=\"--selinux-enabled=false --log-driver=journald --signature-verification=false\"/' /etc/sysconfig/docker

              systemctl enable --now etcd
              etcdctl mkdir /kube-centos/network
              etcdctl mk /kube-centos/network/config "{ \"Network\": \"172.30.30.0/12\", \"SubnetLen\": 24, \"Backend\": { \"Type\": \"vxlan\" } }"
              systemctl daemon-reload
              systemctl restart etcd

              systemctl enable --now kube-apiserver
              cat <<EOF >> /usr/lib/systemd/system/kube-apiserver.service
              [Service]
              PermissionsStartOnly=yes
              ExecStartPre=/usr/bin/mkdir -p /var/run/kubernetes
              ExecStartPre=/usr/bin/chown kube.kube /var/run/kubernetes
              EOF
              systemctl daemon-reload
              systemctl restart kube-apiserver

              for service in kube-controller-manager flanneld kube-scheduler docker kube-proxy kubelet; do 
                systemctl enable --now $service
              done

              kubectl config set-cluster default-cluster --server=http://k8s-master:8080
              kubectl config set-context default-context --cluster=default-cluster --user=default-admin
              kubectl config use-context default-context

              systemctl is-system-running
              for service in etcd kube-apiserver kube-controller-manager flanneld kube-scheduler docker kube-proxy kubelet; do 
                systemctl status -l $service
              done

              kubectl get nodes
            params:
              ostack_auth_url: { get_param: ostack_auth-url }
              ostack_tenant:   { get_param: ostack_tenant   }
              ostack_username: { get_param: ostack_username }
              ostack_password: { get_param: ostack_password }


  k8s_nodes:
    type: OS::Heat::AutoScalingGroup
    depends_on:
      - k8s_master
    properties:
      min_size: 1
      desired_capacity: { get_param: k8s_node_count }
      max_size: 6
      resource:
        type: OS::Nova::Server
        properties:
          image:    { get_param: image   }
          flavor:   { get_param: flavor  }
          key_name: { get_param: keyname }
          networks: 
          - network: { get_param: network_resource }
          scheduler_hints: { group: { get_resource: server_group } }
          metadata: 
            kube_group: k8snode,k8scluster,nofloating
          # user_data_format: RAW
          # user_data:
          #   str_replace:
          #     template: |
          #       #cloud-config
          #       system_info:
          #         users:
          #           - default
          #           - name: minion
          #             gecos: Kubernetes Interactive User
          #             groups: [wheel, adm, systemd-journal]
          #             lock_passwd: true
          #             sudo: ["ALL=(ALL) NOPASSWD:ALL"]
          #             shell: /bin/bash
          #       packages:
          #         - python
          #         - kubernetes-node
          #         - flannel
          #       bootcmd:
          #         - setenforce 0 
          #         - sed -i 's/SELINUX=.*/SELINUX=permissive/' /etc/selinux/config
          #       runcmd:
          #         - sudo su -
          #         - sed -i "s/KUBE_MASTER=.*/KUBE_MASTER=\"--master=http:\/\/%masterip%:8080\"/" /etc/kubernetes/config 
          #         - sed -i "s/KUBE_API_SERVER=.*/KUBE_API_SERVER=\"--api-servers=http:\/\/%masterip%:8080\"/" /etc/kubernetes/kubelet 
          #         - sed -i 's/KUBELET_ADDRESS=.*/KUBELET_ADDRESS=\"--address=0.0.0.0\"/' /etc/kubernetes/kubelet 
          #         - sed -i 's/KUBELET_HOSTNAME=.*/KUBELET_HOSTNAME=\"\"/' /etc/kubernetes/kubelet 
          #         - sed -i "s/FLANNEL_ETCD=.*/FLANNEL_ETCD="http:\/\/%masterip%:2379\"/" /etc/sysconfig/flanneld
          #         - sed -i 's/ServiceAccount,//' /etc/kubernetes/apiserver
          #         - systemctl daemon-reload && systemctl enable --now kubelet docker kube-proxy && systemctl status kubelet docker kube-proxy
          #         - systemctl daemon-reload && systemctl enable --now flanneld && systemctl status flanneld
          #         - kubectl get all --all-namespaces=true
          #       final_message: "The system is up, after $UPTIME seconds. Master Node is @ %masterip%"
          #     params:
          #       "%masterip%": {get_attr: [kube_master_floating, ip]}

outputs:
  ssh_key_name:
    description: >
      Use this ssh in the command line script to log in to the Kubernetes master via ssh (ssh -i .ssh/<ssh_key_name>.pem fedora@<kube_masterip>).
      Get the keypair .pem file from 'Access & Security' and place in the .ssh folder on your computer.
    value: {get_param: keyname}

  kube_masterip:
    description: >
      This is the public ip address of the Kubernetes master server.
      Use this address to log in to the Kubernetes master via ssh. 
    value: {get_attr: [kube_master_floating, ip]}

  dashboard_links:
    description: > 
      Links for the various dashboards are as follows:
    value: "Pending"

  scale_up_url:
    description: >
      This URL is the webhook to scale up the autoscaling group.  You
      can invoke the scale-up operation by doing an HTTP POST to this
      URL; no body nor extra headers are needed.
    value: {get_attr: [scale_up_policy, alarm_url]}

  scale_dn_url:
    description: >
      This URL is the webhook to scale down the autoscaling group.
      You can invoke the scale-down operation by doing an HTTP POST to
      this URL; no body nor extra headers are needed.
    value: {get_attr: [scale_down_policy, alarm_url]}