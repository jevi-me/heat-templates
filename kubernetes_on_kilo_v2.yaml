heat_template_version: 2015-04-30

description: '''
  Boot a Kubernetes cluster with a single master and one or more minions (as specified)
  OpenStack Powered Cloud using Centos 2017-02'''

parameter_groups:
- label: credentials
  description: Parameters
  parameters: 
  - ostack_password
  - ostack_username
  - ostack_auth_url
  - ostack_tenant
- label: node_details
  description: Node customisation
  parameters:
  - image
  - flavor
  - k8s_minion_count
  - minion_volume_size
- label: network_details
  description: Network customisation
  parameters:
  - keyname
  - network_resource
  - ext_network

parameters:

  ostack_auth_url:
    description: Obtain from Compute > Access & Security > API Access
    label: Openstack Auth URL
    type: string
    default: https://west.cloud.computecanada.ca:5000/v2.0
    hidden: false

  ostack_tenant:
    description: Obtain from Compute > Access & Security > API Access > Download Openstack RC
    label: Tenant ID
    type: string
    hidden: false

  ostack_username: 
    description: Repeat your username
    label: Reenter username
    type: string
    hidden: false

  ostack_password: 
    description: Reenter password.
    label: Reenter Password
    type: string
    hidden: true

  flavor:
    description: Flavor used for all instances
    label: Flavor
    type: string
    default: 083093b3-ffc1-464e-a453-cefce795021b
    hidden: false
    constraints:
    - custom_constraint: nova.flavor
    description: Valid flavors only

  image:
    description: Image that will be used for the nodes.
    label: Image
    type: string
    default: 83867183-2096-4d41-945b-953a5876b575
    hidden: false
    constraints: 
    - custom_constraint: glance.image
    description: Must be a valid Glance image

  k8s_minion_count:
    description: Number of machines to deploy as a Kubernetes Minion
    label: Kubernetes Minion Count
    type: number
    default: 1
    hidden: false
    constraints:
    - range:
        min: 1
        max: 6
      description: Must be between 2 and 6 machines.

  ext_network:
    description: See Routers tab for name of the External Network
    type: string
    label: External Network
    default: VLAN3337
    hidden: false

  keyname:
    description: Name of keypair to be used for instance
    label: Key Pair
    type: string
    default: dtnode_key
    hidden: false
    constraints: 
    - custom_constraint: nova.keypair
    description: Must be a known keypair

  network_resource:
    description: WestGrid project network
    label: Network
    type: string
    default: a7741f95-0bc1-4424-86ef-2e8f66bcae18
    hidden: false
    constraints:
    - custom_constraint: neutron.network
    description: Must be a valid Neutron Network.

  minion_volume_size:
    description: Size of a cinder volume to allocate to the minions for container/image storage
    label: Minion Volume Size
    type: number
    default: 8
    hidden: false
    constraints:
    - range:
        min: 4
        max: 20
    description: Must be between 4 and 20

resources:
  ########################################
  ##  Policies, Groups and IPs
  ########################################

  server_group:
    type: OS::Nova::ServerGroup
    properties:
      name: nova-server-group

  k8s_master_floating:
    type: OS::Nova::FloatingIP
    properties:
      pool: {get_param: ext_network}

  k8s_master_floating_association:
    type: OS::Nova::FloatingIPAssociation
    depends_on:
      - k8s_master
    properties:
      floating_ip: {get_resource: k8s_master_floating}
      server_id: {get_resource: k8s_master}

  cluster_access:
     type: OS::Neutron::SecurityGroup
     properties:
       name: cluster_access
       rules:
         - remote_ip_prefix: 0.0.0.0/0
           protocol: tcp
           port_range_min: 22
           port_range_max: 22
         - remote_ip_prefix: 0.0.0.0/0
           protocol: tcp
           port_range_min: 10250
           port_range_max: 10255
         - remote_ip_prefix: 0.0.0.0/0
           protocol: tcp
           port_range_min: 2379
           port_range_max: 2380
         - remote_ip_prefix: 0.0.0.0/0
           protocol: tcp
           port_range_min: 6443
           port_range_max: 6443
         - remote_ip_prefix: 0.0.0.0/0
           protocol: tcp
           port_range_min: 30000
           port_range_max: 32767
         - remote_ip_prefix: 0.0.0.0/0
           protocol: tcp
           port_range_min: 1
           port_range_max: 65535
         - remote_ip_prefix: 0.0.0.0/0
           protocol: udp
           port_range_min: 1
           port_range_max: 65535
         - remote_ip_prefix: 0.0.0.0/0
           protocol: icmp

  ########################################
  ##  Servers
  ########################################
  k8s_master:
    type: OS::Nova::Server
    properties:
      name: k8s_master
      image:    { get_param: image   }
      flavor:   { get_param: flavor  }
      key_name: { get_param: keyname }
      networks: 
      - network: { get_param: network_resource }
      scheduler_hints: { group: { get_resource: server_group } }
      security_groups: 
      - default
      - get_resource: cluster_access
      metadata: 
        kube_group: k8scluster,vault,nofloating
      user_data_format: RAW
      user_data:
        str_replace:
          template: |
            #!/bin/bash
            os_inits() {
              systemctl disable firewalld
              sed -i 's/SELINUX=.*/SELINUX=disabled/' /etc/selinux/config
              yum remove chrony -y -q
              yum install ntp -y -q
              systemctl enable ntpd.service
              systemctl start ntpd.service
            }
            package_install() {
              yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/kubernetes-client-1.1.0-0.4.git2bfa9a1.el7.x86_64.rpm -y -q
              yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/kubernetes-master-1.1.0-0.4.git2bfa9a1.el7.x86_64.rpm -y -q
              yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/kubernetes-node-1.1.0-0.4.git2bfa9a1.el7.x86_64.rpm -y -q 
              yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/kubernetes-1.1.0-0.4.git2bfa9a1.el7.x86_64.rpm -y -q
              yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/etcd-2.0.9-1.el7.x86_64.rpm -y -q
              yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/flannel-0.2.0-7.el7.x86_64.rpm -y -q
            }
            config_host() {
              masterip=$(ip addr show eth0 | awk '$1 == "inet" {print $2}' | cut -f1 -d/)
              cat <<EOF >> /etc/hosts
              $masterip    k8s-master.westcloud
              $masterip    k8s-master
              EOF
            }
            backup_files() {
              mkdir /etc/kubernetes/originals-backup
              echo "This folder contains the original copies of all files modified by this script." > /etc/kubernetes/originals-backup/readme.txt
              cp /etc/kubernetes/apiserver /etc/kubernetes/originals-backup/apiserver
              cp /etc/kubernetes/config /etc/kubernetes/originals-backup/config
              cp /etc/etcd/etcd.conf /etc/kubernetes/originals-backup/etcd.conf
              cp /etc/kubernetes/kubelet /etc/kubernetes/originals-backup/kubelet
              cp /etc/sysconfig/flanneld /etc/kubernetes/originals-backup/flanneld
              cp /etc/kubernetes/controller-manager /etc/kubernetes/originals-backup/controller-manager
              cp /etc/sysconfig/docker  /etc/kubernetes/originals-backup/docker
            }
            config_files() {
              cat <<EOF > /etc/kubernetes/apiserver
              # The address on the local server to listen to.
              KUBE_API_ADDRESS="--insecure-bind-address=0.0.0.0"
              # The port on the local server to listen on.
              KUBE_API_PORT="--port=8080"
              # Port minions listen on
              KUBELET_PORT="--kubelet-port=10250"
              # Comma separated list of nodes in the etcd cluster
              KUBE_ETCD_SERVERS="--etcd-servers=http://k8s-master:2379"
              # Address range to use for services
              KUBE_SERVICE_ADDRESSES="--service-cluster-ip-range=10.254.0.0/16"
              # default admission control policies
              KUBE_ADMISSION_CONTROL="--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota"
              # Add your own!
              KUBE_API_ARGS=""
              EOF
              cat <<EOF > /etc/kubernetes/config
              # logging to stderr means we get it in the systemd journal
              KUBE_LOGTOSTDERR="--logtostderr=true"
              # journal message level, 0 is debug
              KUBE_LOG_LEVEL="--v=0"
              # Should this cluster be allowed to run privileged docker containers
              KUBE_ALLOW_PRIV="--allow-privileged=false"
              # How the controller-manager, scheduler, and proxy find the apiserver
              KUBE_MASTER="--master=http://k8s-master:8080"
              EOF
              cat <<EOF > /etc/etcd/etcd.conf
              # [member]
              ETCD_NAME=default
              ETCD_DATA_DIR="/var/lib/etcd/default.etcd"
              ETCD_LISTEN_CLIENT_URLS="http://0.0.0.0:2379"
              #[cluster]
              ETCD_ADVERTISE_CLIENT_URLS="http://0.0.0.0:2379"
              EOF
              cat <<EOF > /etc/kubernetes/kubelet
              # The address for the info server to serve on (set to 0.0.0.0 or "" for all interfaces)
              KUBELET_ADDRESS="--address=0.0.0.0"
              # You may leave this blank to use the actual hostname
              KUBELET_HOSTNAME=""
              # location of the api-server
              KUBELET_API_SERVER="--api-servers=http://k8s-master:8080"
              # Add your own!
              KUBELET_ARGS=""
              EOF
              cat <<EOF > /etc/kubernetes/cloud.conf
              [Global]
              auth-url=%ostack_auth_url%
              tenant-id=%ostack_tenant% 
              username=%ostack_username%
              password=%ostack_password%
              EOF
              cat <<EOF > /etc/sysconfig/flanneld
              # etcd url location.  Point this to the server where etcd runs
              FLANNEL_ETCD="http://k8s-master:2379"
              # etcd config key.  This is the configuration key that flannel queries
              # For address range assignment
              FLANNEL_ETCD_KEY="/kube-centos/network"
              EOF
              sed -i 's/KUBE_CONTROLLER_MANAGER_ARGS=.*/KUBE_CONTROLLER_MANAGER_ARGS=\"--cloud-provider=openstack --cloud-config=\/etc\/kubernetes\/cloud.conf\"/' /etc/kubernetes/controller-manager
              sed -i 's/OPTIONS=.*/OPTIONS=\"--selinux-enabled=false --log-driver=journald --signature-verification=false\"/' /etc/sysconfig/docker
            }
            enable_services() {
              systemctl enable --now etcd
              etcdctl mkdir /kube-centos/network
              etcdctl mk /kube-centos/network/config "{ \"Network\": \"172.30.30.0/12\", \"SubnetLen\": 24, \"Backend\": { \"Type\": \"vxlan\" } }"
              systemctl daemon-reload
              systemctl restart etcd
              systemctl enable --now kube-apiserver
              cat <<EOF >> /usr/lib/systemd/system/kube-apiserver.service
              [Service]
              PermissionsStartOnly=yes
              ExecStartPre=/usr/bin/mkdir -p /var/run/kubernetes
              ExecStartPre=/usr/bin/chown kube.kube /var/run/kubernetes
              EOF
              systemctl daemon-reload
              systemctl restart kube-apiserver
              for service in kube-controller-manager flanneld kube-scheduler docker kube-proxy kubelet; do 
              systemctl enable --now $service
              done
              kubectl config set-cluster default-cluster --server=http://k8s-master:8080
              kubectl config set-context default-context --cluster=default-cluster --user=default-admin
              kubectl config use-context default-context
              systemctl is-system-running
              for service in etcd kube-apiserver kube-controller-manager flanneld kube-scheduler docker kube-proxy kubelet; do 
              systemctl status -l $service
              done
            }
            kube_checks() {
              kubectl get nodes
              systemctl --state=failed
            }
            create_services() {
              kubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml
              kubectl create -f https://raw.githubusercontent.com/giantswarm/kubernetes-prometheus/master/manifests-all.yaml
              kubectl get all --all-namespaces=true
            }
            sleep 10
            os_inits
            sleep 10
            package_install
            sleep 10
            config_host
            sleep 10
            backup_files
            sleep 10
            config_files
            sleep 10
            enable_services
            sleep 10
            kube_checks
            sleep 10
            create_services
          params:
            "%ostack_auth_url%": { get_param: ostack_auth_url }
            "%ostack_tenant%":   { get_param: ostack_tenant   }
            "%ostack_username%": { get_param: ostack_username }
            "%ostack_password%": { get_param: ostack_password }

  k8s_minions:
    type: OS::Heat::ResourceGroup
    depends_on:
      - k8s_master
    properties:
      count: { get_param: k8s_minion_count }
      resource_def:
        type: OS::Nova::Server
        properties:
          image:    { get_param: image   }
          flavor:   { get_param: flavor  }
          key_name: { get_param: keyname }
          name: k8s_minion_%index%
          networks: 
          - network: { get_param: network_resource }
          scheduler_hints: { group: { get_resource: server_group } }
          metadata: 
            kube_group: k8sminion,k8scluster,nofloating
          user_data_format: RAW
          user_data:
            str_replace:
              template: |
                #!/bin/sh
                os_inits() {
                  systemctl disable firewalld
                  sed -i 's/SELINUX=.*/SELINUX=disabled/' /etc/selinux/config
                  yum remove chrony -y -q
                  yum install ntp -y -q
                  systemctl enable ntpd.service
                  systemctl start ntpd.service
                }
                package_install() {
                  yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/kubernetes-client-1.1.0-0.4.git2bfa9a1.el7.x86_64.rpm -y -q
                  yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/kubernetes-master-1.1.0-0.4.git2bfa9a1.el7.x86_64.rpm -y -q
                  yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/kubernetes-node-1.1.0-0.4.git2bfa9a1.el7.x86_64.rpm -y -q 
                  yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/kubernetes-1.1.0-0.4.git2bfa9a1.el7.x86_64.rpm -y -q
                  yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/etcd-2.0.9-1.el7.x86_64.rpm -y -q
                  yum install https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/Packages/flannel-0.2.0-7.el7.x86_64.rpm -y -q
                }
                config_host() {
                  nodeip=$(ip addr show eth0 | awk '$1 == "inet" {print $2}' | cut -f1 -d/)
                  cat <<EOF >> /etc/hosts
                  $nodeip    k8s-node-%index%.westcloud
                  $nodeip    k8s-node-%index%
                  %masterip%  k8s-master.westcloud
                  %masterip%  k8s-master
                  EOF
                }
                backup_files(){
                  mkdir /etc/kubernetes/originals-backup
                  echo "This folder contains the original copies of all files modified by this script." > /etc/kubernetes/originals-backup/readme.txt
                  cp /etc/kubernetes/config /etc/kubernetes/originals-backup/config
                  cp /etc/kubernetes/kubelet /etc/kubernetes/originals-backup/kubelet
                  cp /etc/sysconfig/flanneld /etc/kubernetes/originals-backup/flanneld
                  cp /etc/sysconfig/docker  /etc/kubernetes/originals-backup/docker
                }
                config_files() {
                  cat <<EOF > /etc/kubernetes/config
                  # logging to stderr means we get it in the systemd journal
                  KUBE_LOGTOSTDERR="--logtostderr=true"
                  # journal message level, 0 is debug
                  KUBE_LOG_LEVEL="--v=0"
                  # Should this cluster be allowed to run privileged docker containers
                  KUBE_ALLOW_PRIV="--allow-privileged=false"
                  # How the controller-manager, scheduler, and proxy find the apiserver
                  KUBE_MASTER="--master=http://k8s-master:8080"
                  EOF
                  cat <<EOF > /etc/sysconfig/flanneld
                  # etcd url location.  Point this to the server where etcd runs
                  FLANNEL_ETCD="http://k8s-master:4001"
                  # etcd config key.  This is the configuration key that flannel queries
                  # For address range assignment
                  FLANNEL_ETCD_KEY="/kube-centos/network"
                  EOF
                  cat <<EOF > /etc/kubernetes/kubelet
                  # The address for the info server to serve on (set to 0.0.0.0 or "" for all interfaces)
                  KUBELET_ADDRESS="--address=0.0.0.0"
                  # You may leave this blank to use the actual hostname
                  KUBELET_HOSTNAME=""
                  # location of the api-server
                  KUBELET_API_SERVER="--api-servers=http://k8s-master:8080"
                  # Add your own!
                  KUBELET_ARGS=""
                  EOF
                  sed -i 's/OPTIONS=.*/OPTIONS=\"--selinux-enabled=false --log-driver=journald --signature-verification=false\"/' /etc/sysconfig/docker
                }
                enable_services() {
                  for services in kube-proxy kublet flanneld docker; do
                    systemctl enable --now $services
                  done
                  kubectl config set-cluster default-cluster --server=http://k8s-master:8080
                  kubectl config set-context default-context --cluster=default-cluster --user=default-admin
                  kubectl config use-context default-context
                  systemctl is-system-running
                  for service in kube-proxy kublet flanneld docker; do
                    systemctl status -l $service
                  done
                  kubectl get nodes
                }
                sleep 10
                os_inits
                sleep 10
                package_install
                sleep 10
                config_host
                sleep 10
                backup_files
                sleep 10
                config_files
                sleep 10
                enable_services
              params: 
                "%masterip%": {get_attr: [k8s_master_floating, ip]}

  ########################################
  ##  Volumes
  ########################################
  master_vol:
    type: OS::Cinder::Volume
    properties:
      size: 8

  master_vol_attach:
    type: OS::Cinder::VolumeAttachment
    properties:
      instance_uuid: {get_resource: k8s_master}
      volume_id: {get_resource: master_vol}

  minion_vols:
    type: OS::Heat::ResourceGroup
    properties:
      count: { get_param: k8s_minion_count }
      resource_def:
        type: OS::Cinder::Volume
        properties:
          size: { get_param: minion_volume_size}

  minion_vols_attach:
      type: OS::Heat::ResourceGroup
      properties:
        count: { get_param: k8s_minion_count }
        resource_def:
          type: OS::Cinder::VolumeAttachment
          properties:
            instance_uuid: { get_attr: [k8s_minions,resources.0] }
            volume_id:     { get_attr: [minion_vols,resources.0] }

outputs:
  ssh_key_name:
    description: >
      Use this ssh in the command line script to log in to the Kubernetes master via ssh (ssh -i .ssh/<ssh_key_name>.pem fedora@<kube_masterip>).
      Get the keypair .pem file from 'Access & Security' and place in the .ssh folder on your computer.
    value: {get_param: keyname}

  k8s_masterip:
    description: >
      This is the public ip address of the Kubernetes master server.
      Use this address to log in to the Kubernetes master via ssh. 
    value: {get_attr: [k8s_master_floating, ip]}

  features_lists:
    description: > 
      List of features enabled:
    value: "- Prometheus, Grafana,Flannel"