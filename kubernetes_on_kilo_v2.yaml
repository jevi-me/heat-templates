heat_template_version: 2015-04-30

description: '''
  Boot a Kubernetes cluster with a single master and one or more nodes (as specified)
  OpenStack Powered Cloud.'''

parameters:

  flavor:
    description: Flavor used for instances
    label: Flavor
    type: string
    default: "p1-1.5gb"
    hidden: false
    constraints:
    - custom_constraint: nova.flavor
    description: Valid flavors only

  image:
    description: Image that will be used for the nodes.
    label: Image
    type: string
    default: "fedora-cloud-28"
    hidden: false
    constraints: 
    - custom_constraint: glance.image
    description: Must be a valid Glance image

  k8s_node_count:
    description: Number of machines to deploy as a Kubernetes Minion
    label: Kubernetes Minion Count
    type: number
    default: 3
    hidden: false
    constraints:
    - range:
        min: 1
        max: 6
      description: Must be between 2 and 6 machines.

  keyname:
    description: Name of keypair to be used for instance
    label: Key Pair
    type: string
    default: dtnode_key
    hidden: false
    constraints: 
    - custom_constraint: nova.keypair
    description: Must be a known keypair

  network_resource:
    description: WestGrid project network
    label: Network
    type: string
    default: "jwe-314_network"
    hidden: false
    constraints:
    - custom_constraint: neutron.network
    description: Must be a valid Neutron Network.


  fixed_network_cidr:
    type: string
    description: network range for fixed ip network
    default: 10.0.0.0/24

  portal_network_cidr:
    type: string
    description: >
      address range used by kubernetes for service portals
    default: 10.254.0.0/16

  flannel_network_cidr:
    type: string
    description: network range for flannel overlay network
    default: 10.100.0.0/16

  flannel_network_subnetlen:
    type: string
    description: size of subnet assigned to each node
    default: 24

  flannel_use_vxlan:
    type: string
    description: >
      if true use the vxlan backend, otherwise use the default
      udp backend
    default: "false"
    constraints:
      - allowed_values: ["true", "false"]

  kube_allow_priv:
    type: string
    description: >
      whether or not kubernetes should permit privileged containers.
    default: "true"
    constraints:
      - allowed_values: ["true", "false"]

  docker_volume_size:
    type: number
    description: >
      size of a cinder volume to allocate to docker for container/image
      storage
    default: 25

  wait_condition_timeout:
    type: number
    description : >
      timeout for the Wait Conditions
    default: 6000

  scale_up_period_length:
    type: number
    default: 60

  scale_up_period_count:
    type: number
    default: 1

  scale_up_threshold:
    type: number
    default: 70

  scale_down_period_length:
    type: number
    default: 600

  scale_down_period_count:
    type: number
    default: 1

  scale_down_threshold:
    type: number
    default: 15

  scale_up_cooldown:
    type: number
    default: 120

  scale_down_cooldown:
    type: number
    default: 60

resources:
  checkpoint:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ungrouped
      config: |
        #!/bin/bash
        echo ">> CHECKPOINT!"

  install_kubernetes:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ungrouped
      config: |
        #!/bin/bash
        echo ">> START install kubernetes and flanneld ..."
        sudo dnf -y install kubernetes
        SUDO dnf -y install flannel
        echo ">> ... END install kubernetes and flanneld"

  install_etcd:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ungrouped
      config: |
        #!/bin/bash
        echo ">> START etcd ..."        
        sudo dnf -y install etcd
        echo ">> ... END install etcd"

  write_heat_params:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ungrouped
      config: |
        #cloud-config
        write_files:
        - path: /etc/sysconfig/heat-params
          owner: "root:root"
          permissions: "0644"
          content: |
            KUBE_ALLOW_PRIV="FALSE"
            FLANNEL_NETWORK_CIDR="10.0.0.0/24"
            FLANNEL_NETWORK_SUBNETLEN="24"
            FLANNEL_USE_VXLAN="FALSE"
            PORTAL_NETWORK_CIDR="10.254.0.0/16"

  atomic_upgrade:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ungrouped
      config: |
        #cloud-config
        bootcmd:
          - |
        test -f /etc/upgrade-flag ||
        { rm -rf /var/lib/cloud/instances/*;
        rpm-ostree upgrade > /var/log/ostree-upgrade.log 2>&1;
        touch /etc/upgrade-flag;
        reboot; }

  configure_etcd:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ungrouped
      config: |
        #!/bin/s
        myip=$(ip addr show eth0 |
        awk '$1 == "inet" {print $2}' | cut -f1 -d/)
        cat > /etc/etcd/etcd.conf <<EOF
        # [member]
        ETCD_NAME=default
        ETCD_DATA_DIR="/var/lib/etcd/default.etcd"
        ETCD_LISTEN_CLIENT_URLS="http://0.0.0.0:4001"
        [cluster]
        ETCD_ADVERTISE_CLIENT_URLS="http://$myip:4001"
        
        EOF

  configure_docker_storage:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ungrouped
      config: |
        #!/bin/bash
        . /etc/sysconfig/heat-params
        DOCKER_DEV=/dev/disk/by-id/virtio-${DOCKER_VOLUME:0:20}
        attempts=60
        while [[ ! -b $DOCKER_DEV && $attempts != 0 ]]; do
          echo "waiting for disk $DOCKER_DEV"
          sleep 0.5
          udevadm trigger
          let attempts--
        done
        if ! [ -b $DOCKER_DEV ]; then
          echo "ERROR: device $DOCKER_DEV does not exist" >&2
          exit 1
        fi
        pvcreate $DOCKER_DEV
        vgcreate docker $DOCKER_DEV
        cat > /etc/sysconfig/docker-storage-setup <<EOF
        VG=docker
        EOF

  configure_kubernetes:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ungrouped
      config: |
        #!/bin/sh
        . /etc/sysconfig/heat-params
        echo "configuring kubernetes (master)"
        sed -i '
          /^KUBE_ALLOW_PRIV=/ s/=.*/="--allow_privileged='"$KUBE_ALLOW_PRIV"'"/
        ' /etc/kubernetes/config
        sed -i '
          /^KUBE_API_ADDRESS=/ s/=.*/="--address=0.0.0.0"/
          /^KUBE_SERVICE_ADDRESSES=/ s|=.*|="--portal_net='"$PORTAL_NETWORK_CIDR"'"|
        ' /etc/kubernetes/apiserver
        sed -i '
          /^KUBELET_ADDRESSES=/ s/=.*/="--machines='""'"/
        ' /etc/kubernetes/controller-manager

  configure_kubernetes_node:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ungrouped
      config: |
        #!/bin/sh
        . /etc/sysconfig/heat-params
        echo "configuring kubernetes (minion)"
        myip=$(ip addr show eth0 |
        awk '$1 == "inet" {print $2}' | cut -f1 -d/)
        myip_last_octet=${myip##*.}
        sed -i '
        /^KUBE_ALLOW_PRIV=/ s/=.*/="--allow_privileged='"$KUBE_ALLOW_PRIV"'"/
        /^KUBE_ETCD_SERVERS=/ s|=.*|="--etcd_servers=http://'"$KUBE_MASTER_IP"':4001"|
        /^KUBE_MASTER=/ s/=.*/="--master='"$KUBE_MASTER_IP"':8080"/
        ' /etc/kubernetes/config
        sed -i '
        /^KUBELET_ADDRESS=/ s/=.*/="--address=0.0.0.0"/
        /^KUBELET_HOSTNAME=/ s/=.*/="--hostname_override='"$myip"'"/
        /^KUBELET_API_SERVER=/ s/=.*/="--api_servers='"$KUBE_MASTER_IP"':8080"/
        ' /etc/kubernetes/kubelet
        sed -i '
        /^FLANNEL_ETCD=/ s|=.*|="http://'"$KUBE_MASTER_IP"':4001"|
        ' /etc/sysconfig/flanneld
        cat >> /etc/environment <<EOF
        KUBERNETES_MASTER=http://$KUBE_MASTER_IP:8080
        EOF
        systemctl enable kube-register

  write_flannel_config:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ungrouped
      config: |
        #!/bin/sh
        . /etc/sysconfig/heat-params
        . /etc/sysconfig/flanneld
        FLANNEL_JSON=/etc/sysconfig/flannel-network.json
        if [ "$FLANNEL_USE_VXLAN" == "true" ]; then
          use_vxlan=1
        fi
        # Generate a flannel configuration that we will
        # store into etcd using curl.
        cat > $FLANNEL_JSON <<EOF
        {
          "Network": "$FLANNEL_NETWORK_CIDR",
          "Subnetlen": $FLANNEL_NETWORK_SUBNETLEN
        EOF
        if [ "$use_vxlan" = 1 ]; then
        cat >> $FLANNEL_JSON <<EOF
          ,
          "Backend": {
            "Type": "vxlan"
          }
        EOF
        fi
        cat >> $FLANNEL_JSON <<EOF
        }
        EOF

  flannel_config_service:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ungrouped
      config: |
        #cloud-config
        merge_how: dict(recurse_array)+list(append)
        write_files:
          - path: /usr/local/bin/flannel-config
            owner: "root:root"
            permissions: "0755"
            content: |
              #!/bin/sh
              
              : ${FLANNEL_JSON:=/etc/sysconfig/flannel-network.json}
              if ! [ -f "$FLANNEL_JSON" ]; then
                echo "ERROR: missing network configuration file" >&2
                exit 1
              fi
              if ! [ "$FLANNEL_ETCD" ] && [ "$FLANNEL_ETCD_KEY" ]; then
                echo "ERROR: missing required configuration" >&2
                exit 1
              fi
              
              echo "creating flanneld config in etcd"
              while ! curl -sf -L $FLANNEL_ETCD/v2/keys${FLANNEL_ETCD_KEY}/config \
                -X PUT --data-urlencode value@${FLANNEL_JSON}; do
                  echo "waiting for etcd"
                  sleep 1
              done
          - path: /etc/systemd/system/flannel-config.service
            owner: "root:root"
            permissions: "0644"
            content: |
              [Unit]
              After=etcd.service
              Requires=etcd.service
              [Service]
              Type=oneshot
              EnvironmentFile=/etc/sysconfig/flanneld
              ExecStart=/usr/local/bin/flannel-config
              [Install]
              WantedBy=multi-user.target
        runcmd:
          - systemctl enable flannel-config
          - systemctl start --no-block flannel-config

  enable_services:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ungrouped
      config: |
        #!/bin/sh
        # make sure we pick up any modified unit files
        systemctl daemon-reload
        echo ">> Starting services"
        for service in etcd kube-apiserver kube-scheduler kube-controller-manager flanneld kube-proxy; do
          echo "activating service $service"
          systemctl enable $service
          systemctl --no-block start $service
        done

  kube_user:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ungrouped
      config: |
        #cloud-config
        system_info:
          default_user:
            name: minion
            lock_passwd: true
            gecos: Kubernetes Interactive User
            groups: [wheel, adm, systemd-journal]
            sudo: ["ALL=(ALL) NOPASSWD:ALL"]
            shell: /bin/bash

  kube_examples:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ungrouped
      config: |
        #cloud-config
        merge_how: dict(recurse_array)+list(append)
        write_files:
          - path: /etc/kubernetes/examples/web.replica
            owner: "root:root"
            permissions: "0644"
            content: |
              apiVersion: v1beta3
              kind: ReplicationController
              id: web
              metadata:
                name: web
              spec:
                replicas: 1
                # selector identifies the set of Pods that this
                # replicaController is responsible for managing
                selector:
                  name: web
                # podTemplate defines the 'cookie cutter' used for creating
                # new pods when necessary
                template:
                  metadata:
                    labels:
                      # Important: these labels need to match the selector above
                      # The api server enforces this constraint.
                      name: web
                  spec:
                    containers:
                      - name: web
                        image: larsks/mini-httpd
          - path: /etc/kubernetes/examples/web.service
            owner: "root:root"
            permissions: "0644"
            content: |
              kind: Service
              apiVersion: v1beta1
              id: web
              port: 8000
              selector:
                name: web
              containerPort: 80
              createExternalLoadBalancer: true
          - path: /etc/kubernetes/examples/stress.replica
            owner: "root:root"
            permissions: "0644"
            content: |
              apiVersion: v1beta3
              kind: ReplicationController
              id: stress
              metadata:
                name: stress-controller
              spec:
                replicas: 1
                # selector identifies the set of Pods that this
                # replicaController is responsible for managing
                selector:
                  name: stress
                # podTemplate defines the 'cookie cutter' used for creating
                # new pods when necessary
                template:
                  metadata:
                    labels:
                      # Important: these labels need to match the selector above
                      # The api server enforces this constraint.
                      name: stress
                  spec:
                    containers:
                      - name: stress
                        image: larsks/stress
                        args: ["--cpu", "1"]

  master_wc_notify:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ungrouped
      config: |
        #!/bin/bash -v
        #wc_notify --data-binary '{"status": "SUCCESS"}'
        #params:
        #wc_notify: {get_attr: [master_wait_handle, curl_cli]}

  node_wc_notify:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ungrouped
      config: |
        #!/bin/bash -v
        #wc_notify --data-binary '{"status": "SUCCESS"}'
        #params:
        #wc_notify: {get_attr: [node_wait_handle, curl_cli]}

  disable_selinux:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ungrouped
      config: |
        #cloud-boothook
        #!/bin/sh
        setenforce 0
        sed -i '/^SELINUX=/ s/=.*/=permissive/' /etc/selinux/config

  docker_service:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ungrouped
      config: |
        #cloud-config
        merge_how: dict(recurse_array)+list(append)
        bootcmd:
          - mkdir -p /etc/systemd/system/docker.service.d
          - mkdir -p /etc/systemd/system/flanneld.service.d
        write_files:
          - path: /usr/local/bin/flannel-docker-bridge
            owner: "root:root"
            permissions: "0755"
            content: |
              #!/bin/sh
              if ! [ "$FLANNEL_SUBNET" ] && [ "$FLANNEL_MTU" ] ; then
                echo "ERROR: missing required environment variables." >&2
                exit 1
              fi
              mkdir -p /run/flannel/
              cat > /run/flannel/docker <<EOF
              DOCKER_NETWORK_OPTIONS="--bip=$FLANNEL_SUBNET --mtu=$FLANNEL_MTU"
              EOF
          - path: /etc/systemd/system/flannel-docker-bridge.service
            owner: "root:root"
            permissions: "0644"
            content: |
              [Unit]
              After=flanneld.service
              Before=docker.service
              Requires=flanneld.service
              [Service]
              Type=oneshot
              EnvironmentFile=/run/flannel/subnet.env
              ExecStart=/usr/local/bin/flannel-docker-bridge
              [Install]
              WantedBy=docker.service
          - path: /etc/systemd/system/docker.service.d/flannel.conf
            owner: "root:root"
            permissions: "0644"
            content: |
              [Unit]
              Requires=flannel-docker-bridge.service
              After=flannel-docker-bridge.service
              [Service]
              EnvironmentFile=/run/flannel/docker
          - path: /etc/systemd/system/flanneld.service.d/flannel-docker-bridge.conf
            owner: "root:root"
            permissions: "0644"
            content: |
              [Unit]
              Requires=flannel-docker-bridge.service
              Before=flannel-docker-bridge.service
              [Install]
              Also=flannel-docker-bridge.service




  kube_register:
    type: "OS::Heat::SoftwareConfig"
    properties:
      group: ungrouped
      config: |
        #cloud-config
        merge_how: dict(recurse_array)+list(append)
        write_files:
          - path: /usr/local/bin/kube-register
            permissions: "0755"
            owner: root
            content: |
              #!/bin/sh
              
              . /etc/sysconfig/heat-params
              master_url=http://${KUBE_MASTER_IP}:8080
              myip=$(ip addr show eth0 |
                awk '$1 == "inet" {print $2}' | cut -f1 -d/)
              # wait for master api
              until curl -o /dev/null -sf "${master_url}/healthz"; do
                echo "waiting for kubernetes master"
                sleep 1
              done
              if [ "$1" = "-u" ]; then
              echo "unregistering minion $myip"
              kubectl -s ${master_url} delete minion/$myip
              else
              echo "registering minion $myip"
              cpu=$(($(nproc) * 1000))
              memory=$(awk '/MemTotal: /{print $2 * 1024}' /proc/meminfo)
              cat <<EOF | kubectl create -s ${master_url} -f-
              apiVersion: v1beta1
              id: $myip
              kind: Minion
              resources:
                capacity:
                  cpu: $cpu
                  memory: $memory
              EOF
              fi
          - path: /etc/systemd/system/kube-register.service
            permissions: "0644"
            owner: root
            content: |
              [Unit]
              Description=Register/unregister this node with the Kubernetes master
              Requires=kubelet.service
              After=kubelet.service
              [Service]
              Type=oneshot
              RemainAfterExit=yes
              ExecStart=/usr/local/bin/kube-register
              ExecStop=/usr/local/bin/kube-register -u
              [Install]
              WantedBy=kubelet.service

  kube_master_init:
    type: OS::Heat::MultipartMime
    properties:
      parts:
        - config: {get_resource: disable_selinux}
        - config: {get_resource: atomic_upgrade}
        - config: {get_resource: install_kubernetes}
        - config: {get_resource: install_etcd}
        - config: {get_resource: write_heat_params}
        - config: {get_resource: checkpoint}
        - config: {get_resource: configure_etcd}
        - config: {get_resource: checkpoint}
        - config: {get_resource: kube_user}
        - config: {get_resource: checkpoint}
        - config: {get_resource: configure_kubernetes}
        - config: {get_resource: checkpoint}
        - config: {get_resource: enable_services}
        - config: {get_resource: checkpoint}
        - config: {get_resource: write_flannel_config}
        - config: {get_resource: checkpoint}
        - config: {get_resource: flannel_config_service}
        - config: {get_resource: checkpoint}
        - config: {get_resource: kube_examples}
        - config: {get_resource: checkpoint}
        - config: {get_resource: master_wc_notify}
        - config: {get_resource: checkpoint}

  kube_node_init:
    type: OS::Heat::MultipartMime
    properties:
      parts:
        - config: {get_resource: disable_selinux}
        - config: {get_resource: atomic_upgrade}
        - config: {get_resource: install_kubernetes}
        - config: {get_resource: write_heat_params}
        - config: {get_resource: kube_user}
        - config: {get_resource: kube_examples}
        - config: {get_resource: configure_docker_storage}
        - config: {get_resource: kube_register}
        - config: {get_resource: configure_kubernetes_node}
        - config: {get_resource: docker_service}
        - config: {get_resource: enable_services}
        - config: {get_resource: node_wc_notify}

  k8s_master:
    type: OS::Nova::Server
    properties:
      name: k8s_master
      image:    { get_param: image   }
      flavor:   { get_param: flavor  }
      key_name: { get_param: keyname }
      networks: 
      - network: { get_param: network_resource }
      scheduler_hints: { group: { get_resource: server_group } }
      metadata: 
        kube_group: k8scluster,vault,nofloating
      user_data_format: RAW
      user_data: {get_resource: kube_master_init}

  k8s_node:
    type: OS::Heat::AutoScalingGroup
    properties:
      min_size: 1
      desired_capacity: { get_param: k8s_node_count }
      max_size: 6
      resource:
        type: OS::Nova::Server
        properties:
          image:    { get_param: image   }
          flavor:   { get_param: flavor  }
          key_name: { get_param: keyname }
          networks: 
          - network: { get_param: network_resource }
          scheduler_hints: { group: { get_resource: server_group } }
          metadata: 
            kube_group: k8snode,k8scluster,nofloating
          user_data_format: RAW
          user_data: {get_resource: kube_node_init}

  server_group:
    type: OS::Nova::ServerGroup
    properties:
      name: nova-server-group

  scale_up_policy:
    type: OS::Heat::ScalingPolicy
    properties:
      adjustment_type: change_in_capacity
      auto_scaling_group_id: { get_resource: k8s_node }
      cooldown: {get_param: scale_up_cooldown}
      scaling_adjustment: 1

  scale_down_policy:
    type: OS::Heat::ScalingPolicy
    properties:
      adjustment_type: change_in_capacity
      auto_scaling_group_id: { get_resource: k8s_node }
      cooldown: {get_param: scale_down_cooldown}
      scaling_adjustment: -1
